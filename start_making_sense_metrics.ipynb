{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "A script trying to implement and make sense of the different similarity metrics",
   "id": "ed5bd7158353e2c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:17.248305Z",
     "start_time": "2025-08-22T16:09:17.110680Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import os\n",
    "import seaborn as sns\n",
    "import lib.utils_RSA as rsa\n",
    "from lib.algos import *\n",
    "from scipy.spatial import procrustes as scipro\n",
    "import lib.utils_CKA as cka\n",
    "\n",
    "importlib.reload(rsa)\n",
    "importlib.reload(cka)"
   ],
   "id": "e075f365f79fc5f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib.utils_CKA' from '/home/alban/projects/SAYCam_Vs_EGO4D/lib/utils_CKA.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:17.655843Z",
     "start_time": "2025-08-22T16:09:17.336898Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Load in every activation sets\n",
    "dataset = 'ecoVal'\n",
    "models  = ['ego', 'saycam', 'imagenet', 'supervised', 'random', 'resnet']\n",
    "path2activations = f'/home/alban/Documents/activations_datadriven/%s_{dataset}/'\n",
    "\n",
    "imagelists = {}\n",
    "activations = {}\n",
    "for model in models:\n",
    "    with open(join(path2activations%model, 'imagepaths.txt'), 'r') as f:\n",
    "        imagelists[model] = [line.strip() for line in f.readlines()]\n",
    "    activations[model] = np.load(join(path2activations % model, 'cls_tokens.npy'))\n",
    "\n",
    "activations[model].shape"
   ],
   "id": "2d71337dc32989d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28250, 2048)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:17.711619Z",
     "start_time": "2025-08-22T16:09:17.675882Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### check if images were shown in the same order\n",
    "imagelists['ego'] == imagelists['saycam']\n",
    "imagelist = imagelists['ego'] # since they are the same, only consider one list\n",
    "\n",
    "#### check if each category has the same number of images and list all categories in listcats\n",
    "count = 0\n",
    "cat = ''\n",
    "listcat = list()\n",
    "for i, imgp in enumerate(imagelist):\n",
    "    current_cat = imgp.split('/')[7]\n",
    "    if i == 0:\n",
    "        cat = current_cat\n",
    "        listcat.append(current_cat)\n",
    "    if cat != current_cat:\n",
    "        cat = current_cat\n",
    "        listcat.append(current_cat)\n",
    "        count = 1\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "nb_per_cat = count # in val, 50 images per category\n"
   ],
   "id": "effe982fc3df1b1d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:17.792332Z",
     "start_time": "2025-08-22T16:09:17.788408Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### only select one image per category to play with metrics as a toy example\n",
    "#activations_normalized = {}\n",
    "for model in models:\n",
    "    activations[model] = activations[model][::nb_per_cat]\n",
    "    #activations_normalized[model] = activations[model].copy()\n",
    "    #activations_normalized[model]"
   ],
   "id": "94b9dfa0c4f09e51",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One thing I really want to check and understand is the supposed equivalance of linear CKA and RSA wth L2squared similarity (Cf. Williams, 2024)",
   "id": "ab8c36dc84f67f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:18.883711Z",
     "start_time": "2025-08-22T16:09:17.851318Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute RDMs for several metrics\n",
    "RDMs = {}\n",
    "metrics = ['pearson', 'L2', 'L2squared', 'L2_normalize', 'L2squared_normalize']\n",
    "for i, model in enumerate(models):\n",
    "    RDMs[model] = {}\n",
    "    for m, metric in enumerate(metrics):\n",
    "        RDMs[model][metric] = rsa.compute_RDMs(activations[model], metric = metric, display = False, title = f'{model}_{metric}')"
   ],
   "id": "b6538f899c28e18c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:19.058755Z",
     "start_time": "2025-08-22T16:09:19.001807Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute differences between the different RDMs\n",
    "for i, metric1 in enumerate(metrics[:-1]):\n",
    "    for j, metric2 in enumerate(metrics[i+1:]):\n",
    "        diff = list()\n",
    "        for model in models:\n",
    "            diff.append(np.absolute(RDMs[model][metric1] - RDMs[model][metric2]).mean())\n",
    "        print(f'{metric1} VS {metric2} is {[float(x) for x in diff]}')\n"
   ],
   "id": "be9ed9aeb1b1b275",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson VS L2 is [32.50833649008573, 21.752096619386524, 19.497312251897977, 250.87047294266716, 29.655785704871754, 21.271819620116332]\n",
      "pearson VS L2squared is [1110.4616598258192, 503.07821217899874, 407.1868249234052, 64490.55313873477, 1005.489015213966, 499.64711303729115]\n",
      "pearson VS L2_normalize is [0.4731603240540338, 0.4941509335263503, 0.49345840299192517, 0.43963581816421127, 0.438706026560215, 0.05448409964206643]\n",
      "pearson VS L2squared_normalize is [0.7469598067727495, 0.5762094869882597, 0.5928130206757279, 0.8981276257105497, 0.6550420015053967, 0.12124288070142204]\n",
      "L2 VS L2squared is [1077.9532470703125, 481.3262634277344, 387.6894836425781, 64239.67578125, 975.833251953125, 478.3752746582031]\n",
      "L2 VS L2_normalize is [32.03517532348633, 21.257944107055664, 19.00385284423828, 250.4308319091797, 29.217079162597656, 21.23788833618164]\n",
      "L2 VS L2squared_normalize is [31.76137924194336, 21.175886154174805, 18.904499053955078, 249.97230529785156, 29.000741958618164, 21.385046005249023]\n",
      "L2squared VS L2_normalize is [1109.988525390625, 502.58404541015625, 406.693359375, 64490.11328125, 1005.0502319335938, 499.6131591796875]\n",
      "L2squared VS L2squared_normalize is [1109.71484375, 502.5020446777344, 406.59405517578125, 64489.64453125, 1004.8338623046875, 499.76019287109375]\n",
      "L2_normalize VS L2squared_normalize is [0.27384838461875916, 0.09155070036649704, 0.10536397993564606, 0.4585624933242798, 0.33103010058403015, 0.14814913272857666]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In absolute values, we find vastly different RDMs. How about in terms of correlations?",
   "id": "197fb4a9fbb2a0c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:19.659565Z",
     "start_time": "2025-08-22T16:09:19.240456Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute correlaions between the different RDMs\n",
    "for i, metric1 in enumerate(metrics[:-1]):\n",
    "    for j, metric2 in enumerate(metrics[i+1:]):\n",
    "        diff = list()\n",
    "        for model in models:\n",
    "            diff.append(np.round(np.corrcoef(RDMs[model][metric1].flatten(),RDMs[model][metric2].flatten())[0,1], 3))\n",
    "        print(f'{metric1} VS {metric2} is {[float(x) for x in diff]}')\n"
   ],
   "id": "983d5ec744546bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson VS L2 is [0.871, 0.893, 0.899, 0.212, 0.982, 0.567]\n",
      "pearson VS L2squared is [0.849, 0.876, 0.868, 0.13, 1.0, 0.494]\n",
      "pearson VS L2_normalize is [0.948, 0.963, 0.96, 0.952, 0.982, 0.862]\n",
      "pearson VS L2squared_normalize is [1.0, 1.0, 1.0, 1.0, 1.0, 0.846]\n",
      "L2 VS L2squared is [0.959, 0.977, 0.977, 0.984, 0.982, 0.976]\n",
      "L2 VS L2_normalize is [0.894, 0.891, 0.881, 0.28, 1.0, 0.599]\n",
      "L2 VS L2squared_normalize is [0.871, 0.893, 0.899, 0.212, 0.982, 0.588]\n",
      "L2squared VS L2_normalize is [0.787, 0.819, 0.796, 0.161, 0.982, 0.533]\n",
      "L2squared VS L2squared_normalize is [0.85, 0.876, 0.869, 0.13, 1.0, 0.546]\n",
      "L2_normalize VS L2squared_normalize is [0.948, 0.963, 0.96, 0.952, 0.982, 0.982]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We find that the RDMs found using the various metrics are all very correlated, except for supervised and the ResNet trained on Saycam (last model) --> thus an effect of training algorithm and architecture. What does that mean?\n",
    "\n",
    "The highest correlations are found for pearson and L2squared_normaized, showing they are almost perfectly equivalent!"
   ],
   "id": "6c7a40578810c431"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:24.023815Z",
     "start_time": "2025-08-22T16:09:19.777893Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute similarities between models and metrics.\n",
    "sim_metrics = ['cosine', 'pearson'] # We only consider cosine and pearson as similarity metrics for now\n",
    "\n",
    "SIMs = {} # save all similarity values in a dictionary\n",
    "list_sim = {} # save all similarity values in a list to directly compare with CKA later\n",
    "for sm, sim_metric in enumerate(sim_metrics):\n",
    "    SIMs[sim_metric] = {}\n",
    "    list_sim[sim_metric] = {}\n",
    "    for m, metric in enumerate(metrics):\n",
    "        SIMs[sim_metric][metric] = {}\n",
    "        list_sim[sim_metric][metric] = list()\n",
    "        for i, model1 in enumerate(models[:-1]):\n",
    "            SIMs[sim_metric][metric][model1] = {}\n",
    "            for j, model2 in enumerate(models[i+1:]):\n",
    "                SIMs[sim_metric][metric][model1][model2] = float(np.round(rsa.Compute_sim_RDMs(RDMs[model1][metric], RDMs[model2][metric], center = True, metric = sim_metric), 3))\n",
    "                list_sim[sim_metric][metric].append(SIMs[sim_metric][metric][model1][model2])"
   ],
   "id": "cda06f72483a4123",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:24.120658Z",
     "start_time": "2025-08-22T16:09:24.112889Z"
    }
   },
   "cell_type": "code",
   "source": "SIMs['pearson']['L2squared_normalize']",
   "id": "2e14c465391ab088",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ego': {'saycam': 0.654,\n",
       "  'imagenet': 0.516,\n",
       "  'supervised': 0.222,\n",
       "  'random': 0.202,\n",
       "  'resnet': 0.594},\n",
       " 'saycam': {'imagenet': 0.546,\n",
       "  'supervised': 0.25,\n",
       "  'random': 0.175,\n",
       "  'resnet': 0.714},\n",
       " 'imagenet': {'supervised': 0.338, 'random': 0.158, 'resnet': 0.519},\n",
       " 'supervised': {'random': 0.069, 'resnet': 0.199},\n",
       " 'random': {'resnet': 0.172}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.198883Z",
     "start_time": "2025-08-22T16:09:24.325805Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Perform CKA on the activations\n",
    "CKA = {} # save all CKA values in a dictionary\n",
    "list_cka = list() # save all CKA values in a list to directly compare with similarities previously computed\n",
    "for i, model1 in enumerate(models[:-1]):\n",
    "    CKA[model1] = {}\n",
    "    for j, model2 in enumerate(models[i+1:]):\n",
    "        CKA[model1][model2] = float(np.round(cka.linear_CKA(activations[model1], activations[model2]), 3))\n",
    "        list_cka.append(CKA[model1][model2])"
   ],
   "id": "eeb4a228d0307a5a",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.317281Z",
     "start_time": "2025-08-22T16:09:26.306462Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sim_metric in sim_metrics:\n",
    "    for metric in metrics:\n",
    "        print(f'{sim_metric} {metric}')\n",
    "        print(np.corrcoef(np.array(list_sim[sim_metric][metric]), np.array(list_cka))[0,1])"
   ],
   "id": "cb6582a71ed41d7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine pearson\n",
      "0.7675556551781587\n",
      "cosine L2\n",
      "0.8064481082208429\n",
      "cosine L2squared\n",
      "0.825802734019459\n",
      "cosine L2_normalize\n",
      "0.8046142095044818\n",
      "cosine L2squared_normalize\n",
      "0.8036225437516894\n",
      "pearson pearson\n",
      "0.7673820117082668\n",
      "pearson L2\n",
      "0.8072679699495764\n",
      "pearson L2squared\n",
      "0.8257192194639429\n",
      "pearson L2_normalize\n",
      "0.8045336025243421\n",
      "pearson L2squared_normalize\n",
      "0.8034486687991955\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It seems that, indepently of the various similarity measures used here, the resulting similarities are equivalently correlated with a linear CKA, around 0.96.\n",
    "\n",
    "We can look at other metrics, such as CCA and Procrustes"
   ],
   "id": "397b1a9dacefab73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.484124Z",
     "start_time": "2025-08-22T16:09:26.479561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Run custom procrustes analysis\n",
    "#d, Z, T = procrustes(activations['saycam'], activations['ego'])\n",
    "### Run scipy procrustes analysis as a control\n",
    "#mtx1, mtx2, dsci = scipro(activations['saycam'], activations['ego'])\n",
    "#print([d, dsci])\n",
    "### --> Both algos agree with each other, and the disparity measures are pretty high (somewhat unexpectedly)"
   ],
   "id": "ff67dde734ec679c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.627539Z",
     "start_time": "2025-08-22T16:09:26.622287Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f2698f5e4b6c127e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
