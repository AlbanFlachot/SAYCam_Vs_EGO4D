{
 "cells": [
  {
   "metadata": {
    "collapsed": true
   },
   "cell_type": "markdown",
   "source": "A script trying to implement and make sense of the different similarity metrics",
   "id": "ed5bd7158353e2c5"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:55:49.131208Z",
     "start_time": "2025-09-02T13:55:48.964930Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import importlib\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from matplotlib import pyplot as plt\n",
    "from os.path import join\n",
    "import os\n",
    "import seaborn as sns\n",
    "import lib.utils_RSA as rsa\n",
    "from lib.algos import *\n",
    "from scipy.spatial import procrustes as scipro\n",
    "import lib.utils_CKA as cka\n",
    "\n",
    "importlib.reload(rsa)\n",
    "importlib.reload(cka)"
   ],
   "id": "e075f365f79fc5f4",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'lib.utils_CKA' from '/home/alban/projects/SAYCam_Vs_EGO4D/lib/utils_CKA.py'>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:55:52.406429Z",
     "start_time": "2025-09-02T13:55:52.148753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Load in every activation sets\n",
    "dataset = 'ecoVal'\n",
    "models  = ['ego', 'saycam', 'imagenet', 'supervised', 'random', 'resnet']\n",
    "path2activations = f'/home/alban/Documents/activations_datadriven/%s_{dataset}/'\n",
    "\n",
    "imagelists = {}\n",
    "activations = {}\n",
    "for model in models:\n",
    "    with open(join(path2activations%model, 'imagepaths.txt'), 'r') as f:\n",
    "        imagelists[model] = [line.strip() for line in f.readlines()]\n",
    "    activations[model] = np.load(join(path2activations % model, 'cls_tokens.npy'))\n",
    "\n",
    "activations[model].shape"
   ],
   "id": "2d71337dc32989d6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28250, 2048)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:55:58.822285Z",
     "start_time": "2025-09-02T13:55:58.789758Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### check if images were shown in the same order\n",
    "imagelists['ego'] == imagelists['saycam']\n",
    "imagelist = imagelists['ego'] # since they are the same, only consider one list\n",
    "\n",
    "#### check if each category has the same number of images and list all categories in listcats\n",
    "count = 0\n",
    "cat = ''\n",
    "listcat = list()\n",
    "for i, imgp in enumerate(imagelist):\n",
    "    current_cat = imgp.split('/')[7]\n",
    "    if i == 0:\n",
    "        cat = current_cat\n",
    "        listcat.append(current_cat)\n",
    "    if cat != current_cat:\n",
    "        cat = current_cat\n",
    "        listcat.append(current_cat)\n",
    "        count = 1\n",
    "    else:\n",
    "        count += 1\n",
    "\n",
    "nb_per_cat = count # in val, 50 images per category\n"
   ],
   "id": "effe982fc3df1b1d",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:58:41.850128Z",
     "start_time": "2025-09-02T13:58:41.847517Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### only select one image per category to play with metrics as a toy example\n",
    "#activations_normalized = {}\n",
    "for model in models:\n",
    "    activations[model] = activations[model][::nb_per_cat]\n",
    "    #activations_normalized[model] = activations[model].copy()\n",
    "    #activations_normalized[model]"
   ],
   "id": "94b9dfa0c4f09e51",
   "outputs": [],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "One thing I really want to check and understand is the supposed equivalance of linear CKA and RSA wth L2squared similarity (Cf. Williams, 2024)",
   "id": "ab8c36dc84f67f48"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:58:57.067610Z",
     "start_time": "2025-09-02T13:58:54.891123Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute RDMs for several metrics\n",
    "RDMs = {}\n",
    "metrics = ['pearson', 'L2', 'L2squared', 'L2_normalize', 'L2squared_normalize']\n",
    "for i, model in enumerate(models):\n",
    "    RDMs[model] = {}\n",
    "    for m, metric in enumerate(metrics):\n",
    "        RDMs[model][metric] = rsa.compute_RDMs(activations[model], metric = metric, display = False, title = f'{model}_{metric}')"
   ],
   "id": "b6538f899c28e18c",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:58:58.605881Z",
     "start_time": "2025-09-02T13:58:58.551076Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute differences between the different RDMs\n",
    "for i, metric1 in enumerate(metrics[:-1]):\n",
    "    for j, metric2 in enumerate(metrics[i+1:]):\n",
    "        diff = list()\n",
    "        for model in models:\n",
    "            diff.append(np.absolute(RDMs[model][metric1] - RDMs[model][metric2]).mean())\n",
    "        print(f'{metric1} VS {metric2} is {[float(x) for x in diff]}')\n"
   ],
   "id": "be9ed9aeb1b1b275",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson VS L2 is [32.50833649008573, 21.752096619386524, 19.497312251897977, 250.87047294266716, 29.655785704871754, 21.271819620116332]\n",
      "pearson VS L2squared is [1110.4616598258192, 503.07821217899874, 407.1868249234052, 64490.55313873477, 1005.489015213966, 499.64711303729115]\n",
      "pearson VS L2_normalize is [0.4731603240540338, 0.4941509335263503, 0.49345840299192517, 0.43963581816421127, 0.438706026560215, 0.05448409964206643]\n",
      "pearson VS L2squared_normalize is [0.7469598067727495, 0.5762094869882597, 0.5928130206757279, 0.8981276257105497, 0.6550420015053967, 0.12124288070142204]\n",
      "L2 VS L2squared is [1077.9532470703125, 481.3262634277344, 387.6894836425781, 64239.67578125, 975.833251953125, 478.3752746582031]\n",
      "L2 VS L2_normalize is [32.03517532348633, 21.257944107055664, 19.00385284423828, 250.4308319091797, 29.217079162597656, 21.23788833618164]\n",
      "L2 VS L2squared_normalize is [31.76137924194336, 21.175886154174805, 18.904499053955078, 249.97230529785156, 29.000741958618164, 21.385046005249023]\n",
      "L2squared VS L2_normalize is [1109.988525390625, 502.58404541015625, 406.693359375, 64490.11328125, 1005.0502319335938, 499.6131591796875]\n",
      "L2squared VS L2squared_normalize is [1109.71484375, 502.5020446777344, 406.59405517578125, 64489.64453125, 1004.8338623046875, 499.76019287109375]\n",
      "L2_normalize VS L2squared_normalize is [0.27384838461875916, 0.09155070036649704, 0.10536397993564606, 0.4585624933242798, 0.33103010058403015, 0.14814913272857666]\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "In absolute values, we find vastly different RDMs. How about in terms of correlations?",
   "id": "197fb4a9fbb2a0c4"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T13:59:24.957045Z",
     "start_time": "2025-09-02T13:59:24.821554Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute correlaions between the different RDMs\n",
    "print(models)\n",
    "for i, metric1 in enumerate(metrics[:-1]):\n",
    "    for j, metric2 in enumerate(metrics[i+1:]):\n",
    "        diff = list()\n",
    "        for model in models:\n",
    "            diff.append(np.round(np.corrcoef(RDMs[model][metric1].flatten(),RDMs[model][metric2].flatten())[0,1], 3))\n",
    "        print(f'{metric1} VS {metric2} is {[float(x) for x in diff]}')\n"
   ],
   "id": "983d5ec744546bd",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ego', 'saycam', 'imagenet', 'supervised', 'random', 'resnet']\n",
      "pearson VS L2 is [0.871, 0.893, 0.899, 0.212, 0.982, 0.567]\n",
      "pearson VS L2squared is [0.849, 0.876, 0.868, 0.13, 1.0, 0.494]\n",
      "pearson VS L2_normalize is [0.948, 0.963, 0.96, 0.952, 0.982, 0.862]\n",
      "pearson VS L2squared_normalize is [1.0, 1.0, 1.0, 1.0, 1.0, 0.846]\n",
      "L2 VS L2squared is [0.959, 0.977, 0.977, 0.984, 0.982, 0.976]\n",
      "L2 VS L2_normalize is [0.894, 0.891, 0.881, 0.28, 1.0, 0.599]\n",
      "L2 VS L2squared_normalize is [0.871, 0.893, 0.899, 0.212, 0.982, 0.588]\n",
      "L2squared VS L2_normalize is [0.787, 0.819, 0.796, 0.161, 0.982, 0.533]\n",
      "L2squared VS L2squared_normalize is [0.85, 0.876, 0.869, 0.13, 1.0, 0.546]\n",
      "L2_normalize VS L2squared_normalize is [0.948, 0.963, 0.96, 0.952, 0.982, 0.982]\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "We find that the RDMs found using the various metrics are all very correlated, except for supervised and the ResNet trained on Saycam (last model) --> thus an effect of training algorithm and architecture. What does that mean?\n",
    "\n",
    "The highest correlations are found for pearson and L2squared_normaized, showing they are almost perfectly equivalent!"
   ],
   "id": "6c7a40578810c431"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T07:05:07.277934Z",
     "start_time": "2025-09-03T07:05:06.523015Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Compute similarities between models using the various metrics.\n",
    "sim_metrics = ['cosine', 'pearson', 'center_pearson'] # We only consider cosine and pearson as similarity metrics for now\n",
    "\n",
    "SIMs = {} # save all similarity values in a dictionary\n",
    "list_sim = {} # save all similarity values in a list to directly compare with CKA later\n",
    "for sm, sim_metric in enumerate(sim_metrics):\n",
    "    if sim_metric == 'pearson':\n",
    "        center = False\n",
    "    else:\n",
    "        center = True\n",
    "    if sim_metric == 'center_pearson':\n",
    "        simmetric = 'pearson'\n",
    "    else:\n",
    "        simmetric = sim_metric\n",
    "    SIMs[sim_metric] = {}\n",
    "    list_sim[sim_metric] = {}\n",
    "    for m, metric in enumerate(metrics):\n",
    "        SIMs[sim_metric][metric] = {}\n",
    "        list_sim[sim_metric][metric] = list()\n",
    "        for i, model1 in enumerate(models[:-1]):\n",
    "            SIMs[sim_metric][metric][model1] = {}\n",
    "            for j, model2 in enumerate(models[i+1:]):\n",
    "                sim = float(np.round(float(rsa.Compute_sim_RDMs(RDMs[model1][metric], RDMs[model2][metric], center = center, metric = simmetric)), 3))\n",
    "                SIMs[sim_metric][metric][model1][model2] = sim\n",
    "                list_sim[sim_metric][metric].append(float(sim))"
   ],
   "id": "cda06f72483a4123",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-03T07:07:13.557829Z",
     "start_time": "2025-09-03T07:07:13.553361Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print('pearson & L2squared')\n",
    "print(list_sim['pearson']['L2squared'])\n",
    "print('cosine & L2squared')\n",
    "print(list_sim['cosine']['L2squared'])\n",
    "print('centered-pearson & L2squared')\n",
    "print(list_sim['center_pearson']['L2squared'])"
   ],
   "id": "2e14c465391ab088",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pearson & L2squared\n",
      "[0.621, 0.379, 0.081, 0.157, 0.443, 0.367, 0.064, 0.116, 0.592, 0.314, 0.095, 0.299, 0.02, 0.025, 0.069]\n",
      "cosine & L2squared\n",
      "[0.656, 0.497, 0.253, 0.195, 0.56, 0.559, 0.282, 0.176, 0.685, 0.416, 0.164, 0.496, 0.06, 0.243, 0.149]\n",
      "centered-pearson & L2squared\n",
      "[0.656, 0.497, 0.253, 0.195, 0.56, 0.559, 0.282, 0.176, 0.685, 0.416, 0.164, 0.496, 0.06, 0.243, 0.149]\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:07:34.842278Z",
     "start_time": "2025-09-02T17:07:32.537711Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Perform CKA on the activations\n",
    "CKA = {} # save all CKA values in a dictionary\n",
    "list_cka = list() # save all CKA values in a list to directly compare with similarities previously computed\n",
    "for i, model1 in enumerate(models[:-1]):\n",
    "    CKA[model1] = {}\n",
    "    for j, model2 in enumerate(models[i+1:]):\n",
    "        CKA[model1][model2] = float(np.round(cka.linear_CKA(activations[model1], activations[model2]), 3))\n",
    "        list_cka.append(CKA[model1][model2])"
   ],
   "id": "eeb4a228d0307a5a",
   "outputs": [],
   "execution_count": 26
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:07:35.712182Z",
     "start_time": "2025-09-02T17:07:35.706115Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sim_metric in sim_metrics:\n",
    "    for metric in metrics:\n",
    "        print(f'{sim_metric} {metric}')\n",
    "        print(np.corrcoef(np.array(list_sim[sim_metric][metric]), np.array(list_cka))[0,1])"
   ],
   "id": "cb6582a71ed41d7e",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine pearson\n",
      "0.9636555055360286\n",
      "cosine L2\n",
      "0.9668148947776151\n",
      "cosine L2squared\n",
      "0.9687370609694657\n",
      "cosine L2_normalize\n",
      "0.9621501145076792\n",
      "cosine L2squared_normalize\n",
      "0.9635437065120578\n",
      "pearson pearson\n",
      "0.8792020092141342\n",
      "pearson L2\n",
      "0.875860689120937\n",
      "pearson L2squared\n",
      "0.871332181937399\n",
      "pearson L2_normalize\n",
      "0.8930530457901726\n",
      "pearson L2squared_normalize\n",
      "0.8835810522621133\n",
      "center_pearson pearson\n",
      "0.9634542386173426\n",
      "center_pearson L2\n",
      "0.966166233913843\n",
      "center_pearson L2squared\n",
      "0.9687370604544859\n",
      "center_pearson L2_normalize\n",
      "0.9614215835294484\n",
      "center_pearson L2squared_normalize\n",
      "0.9633040745496696\n"
     ]
    }
   ],
   "execution_count": 27
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "It seems that, indepently of the various similarity measures used here, the resulting similarities are equivalently correlated with a linear CKA, around 0.96.\n",
    "\n",
    "But what about actual values?"
   ],
   "id": "397b1a9dacefab73"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-09-02T17:07:50.162156Z",
     "start_time": "2025-09-02T17:07:50.153094Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for sim_metric in sim_metrics:\n",
    "    for metric in metrics:\n",
    "        print(f'{sim_metric} {metric}')\n",
    "        print(np.mean(np.absolute(np.array(list_sim[sim_metric][metric]) - np.array(list_cka))))"
   ],
   "id": "8ef9bd719a852281",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cosine pearson\n",
      "0.051600001076857256\n",
      "cosine L2\n",
      "0.06040001014868419\n",
      "cosine L2squared\n",
      "0.06953333293398221\n",
      "cosine L2_normalize\n",
      "0.049000002443790436\n",
      "cosine L2squared_normalize\n",
      "0.052133337656656904\n",
      "pearson pearson\n",
      "0.09280000101327895\n",
      "pearson L2\n",
      "0.17540000250736873\n",
      "pearson L2squared\n",
      "0.18613333584070207\n",
      "pearson L2_normalize\n",
      "0.08853333523670834\n",
      "pearson L2squared_normalize\n",
      "0.09406666799783706\n",
      "center_pearson pearson\n",
      "0.051666667743523916\n",
      "center_pearson L2\n",
      "0.060933335236708325\n",
      "center_pearson L2squared\n",
      "0.06953333584070205\n",
      "center_pearson L2_normalize\n",
      "0.049533334410190595\n",
      "center_pearson L2squared_normalize\n",
      "0.05240000107685726\n"
     ]
    }
   ],
   "execution_count": 28
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.484124Z",
     "start_time": "2025-08-22T16:09:26.479561Z"
    }
   },
   "cell_type": "code",
   "source": [
    "### Run custom procrustes analysis\n",
    "#d, Z, T = procrustes(activations['saycam'], activations['ego'])\n",
    "### Run scipy procrustes analysis as a control\n",
    "#mtx1, mtx2, dsci = scipro(activations['saycam'], activations['ego'])\n",
    "#print([d, dsci])\n",
    "### --> Both algos agree with each other, and the disparity measures are pretty high (somewhat unexpectedly)"
   ],
   "id": "ff67dde734ec679c",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-08-22T16:09:26.627539Z",
     "start_time": "2025-08-22T16:09:26.622287Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "f2698f5e4b6c127e",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
